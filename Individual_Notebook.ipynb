{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Individual Model Notebook\n",
    "\n",
    "This notebook is a **simplified, production-ready version** of our experimental notebooks. It is designed to:\n",
    "- Present the way we selected the best individual model trained during experimentation.\n",
    "- Run predictions on the full training and test sets.\n",
    "- Explore and select the optimal threshold for classification.\n",
    "- Generate a submission file for the test set.\n",
    "\n",
    "All code here is streamlined for clarity and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T18:06:57.232828Z",
     "start_time": "2025-05-01T18:06:57.223449Z"
    },
    "execution": {
     "iopub.execute_input": "2025-06-03T13:21:44.421665Z",
     "iopub.status.busy": "2025-06-03T13:21:44.421158Z",
     "iopub.status.idle": "2025-06-03T13:21:44.427066Z",
     "shell.execute_reply": "2025-06-03T13:21:44.426274Z",
     "shell.execute_reply.started": "2025-06-03T13:21:44.421638Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Third-party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# PyTorch and related imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# ML utilities\n",
    "import timm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Allow duplicate OpenMP libraries (fixes some multi-threading issues on some systems)\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "- **Device selection**: Automatically uses GPU if available, otherwise falls back to CPU.\n",
    "- **Reproducibility**: Random seeds are set for consistent results across runs.\n",
    "- **Directory paths**: Set up paths for training images, test images and label file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T18:06:57.294265Z",
     "start_time": "2025-05-01T18:06:57.291071Z"
    },
    "execution": {
     "iopub.execute_input": "2025-06-03T13:21:44.435635Z",
     "iopub.status.busy": "2025-06-03T13:21:44.435068Z",
     "iopub.status.idle": "2025-06-03T13:21:44.441117Z",
     "shell.execute_reply": "2025-06-03T13:21:44.440275Z",
     "shell.execute_reply.started": "2025-06-03T13:21:44.435606Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Print available CUDA devices and select device for computation\n",
    "print(f\"CUDA Devices: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_state_42 = torch.Generator().manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train_dir = 'images_train'\n",
    "images_test_dir = 'images_test'\n",
    "labels_dir = 'train_onehot.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "- **Dataset class**: Custom PyTorch Dataset for both training and test images. Handles label loading and image reading.\n",
    "- **Transforms**: Includes augmentations for training and normalization for both train/test.\n",
    "- **Augmentations**: Training images are augmented with color jitter, flips, blur, and random crops to improve generalization.\n",
    "- **Normalization**: Both train and test images are normalized using dataset-specific mean and std values found through EDA.\n",
    "- **Splitting**: The training set is split into train/validation subsets for model selection and threshold tuning.\n",
    "- **Dataloaders**: For full training, validation, and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T18:06:58.886850Z",
     "start_time": "2025-05-01T18:06:57.298770Z"
    },
    "execution": {
     "iopub.execute_input": "2025-06-03T13:21:44.490417Z",
     "iopub.status.busy": "2025-06-03T13:21:44.489707Z",
     "iopub.status.idle": "2025-06-03T13:21:47.589343Z",
     "shell.execute_reply": "2025-06-03T13:21:47.588772Z",
     "shell.execute_reply.started": "2025-06-03T13:21:44.490393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_dim_px = 224\n",
    "\n",
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_csv = None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_training = labels_csv is not None  # True if labels are provided (train/val), False for test\n",
    "\n",
    "        if self.is_training:\n",
    "            self.labels_df = pd.read_csv(labels_csv)\n",
    "            self.filenames = self.labels_df.iloc[:, 0].values\n",
    "            self.labels = self.labels_df.iloc[:, 1:].values.astype('float')\n",
    "        else:\n",
    "            self.filenames = sorted(os.listdir(img_dir))\n",
    "            self.labels = None  # No labels for the test set\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.filenames[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_training:\n",
    "            label = torch.tensor(self.labels[idx])\n",
    "            return image, label\n",
    "        else:\n",
    "            return image, self.filenames[idx]\n",
    "\n",
    "# Define data augmentation and normalization for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((image_dim_px, image_dim_px)),\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1)], p=0.3),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0))], p=0.2),\n",
    "    transforms.RandomApply([transforms.RandomResizedCrop(image_dim_px, scale=(0.9, 1.0), ratio=(1.0, 1.0))], p=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5944, 0.5082, 0.4259], std=[0.2128, 0.2213, 0.2308])\n",
    "])\n",
    "\n",
    "# Only normalization for test/validation\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((image_dim_px, image_dim_px)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5944, 0.5082, 0.4259], std=[0.2128, 0.2213, 0.2308])\n",
    "])\n",
    "\n",
    "full_train_dataset = FoodDataset(images_train_dir, labels_dir, transform=train_transform)\n",
    "test_dataset = FoodDataset(images_test_dir, labels_csv=None, transform=test_transform)\n",
    "\n",
    "# Reproducible train/val split\n",
    "val_ratio = 0.2\n",
    "val_size = int(len(full_train_dataset) * val_ratio)\n",
    "train_size = len(full_train_dataset) - val_size\n",
    "train_indices, val_indices = random_split(range(len(full_train_dataset)), [train_size, val_size], generator=random_state_42)\n",
    "train_dataset = Subset(FoodDataset(images_train_dir, labels_dir, transform=train_transform), train_indices)\n",
    "val_dataset = Subset(FoodDataset(images_train_dir, labels_dir, transform=test_transform), val_indices)\n",
    "\n",
    "# Dataloaders for all datasets\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, generator=random_state_42)\n",
    "full_train_dataloader = DataLoader(full_train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, generator=random_state_42)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Fine-Tuning\n",
    "\n",
    "- **Model**: We use a Swin Transformer (swin_base_patch4_window7_224) from the timm library, pre-trained on ImageNet.\n",
    "- **Layer Freezing**: Most layers are frozen to retain pre-trained features, while later layers and the head are unfrozen for fine-tuning.\n",
    "- **Multi-GPU**: DataParallel is used for efficient training on multiple GPUs if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T13:21:48.523554Z",
     "iopub.status.busy": "2025-06-03T13:21:48.522951Z",
     "iopub.status.idle": "2025-06-03T13:21:50.124335Z",
     "shell.execute_reply": "2025-06-03T13:21:50.123796Z",
     "shell.execute_reply.started": "2025-06-03T13:21:48.523537Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model definition and layer freezing/unfreezing\n",
    "\n",
    "def initialize_model(model_name):\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=498)\n",
    "\n",
    "    # Freeze all layers initially\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Unfreeze later layers and head for fine-tuning\n",
    "    for param in model.layers[2].parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in model.layers[3].parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in model.head.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    model = nn.DataParallel(model)  # Enable multi-GPU training if available\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = initialize_model('swin_base_patch4_window7_224')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters and Optimization\n",
    "\n",
    "- **Loss Function**: Binary cross-entropy with logits, suitable for multi-label classification.\n",
    "- **Optimizer**: Adam with different learning rates for different layers (head and deeper layers).\n",
    "- **Scheduler**: StepLR reduces learning rate during training to help convergence.\n",
    "- **Threshold**: Initial threshold is set to 0.5, but will be optimized later.\n",
    "- **Epochs**: 10 epochs for initial fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T18:06:59.185138Z",
     "start_time": "2025-05-01T18:06:58.963151Z"
    },
    "execution": {
     "iopub.execute_input": "2025-06-03T13:21:50.125414Z",
     "iopub.status.busy": "2025-06-03T13:21:50.125138Z",
     "iopub.status.idle": "2025-06-03T13:21:50.131076Z",
     "shell.execute_reply": "2025-06-03T13:21:50.130380Z",
     "shell.execute_reply.started": "2025-06-03T13:21:50.125393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def initialize_hyperparameters(model):\n",
    "    # This function is not strictly necessary, but can be used to encapsulate hyperparameter initialization\n",
    "    loss_fn = nn.BCEWithLogitsLoss()  # this applies sigmoid inside the loss\n",
    "\n",
    "    optimizer = torch.optim.Adam([ \n",
    "        {'params': model.module.head.parameters(), 'lr': 1e-3},\n",
    "        {'params': model.module.layers[3].parameters(), 'lr': 1e-4},\n",
    "        {'params': model.module.layers[2].parameters(), 'lr': 1e-5},\n",
    "    ])\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "   \n",
    "    return loss_fn, optimizer, scheduler\n",
    "\n",
    "loss_fn, optimizer, scheduler = initialize_hyperparameters(model)\n",
    "\n",
    "classification_threshold = 0.5  # Used as a static benchmark value\n",
    "num_epochs = 10 # 10 epochs is a good starting point for fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold Optimization Utility\n",
    "\n",
    "The `find_optimal_threshold` function sweeps a range of thresholds to:\n",
    "- Find the threshold that maximizes micro-F1 score on the validation set.\n",
    "- Report the mean and standard deviation of F1 across thresholds.\n",
    "\n",
    "This helps select a threshold that balances precision and recall for multi-label classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T18:06:59.225349Z",
     "start_time": "2025-05-01T18:06:59.221950Z"
    },
    "execution": {
     "iopub.execute_input": "2025-06-03T13:21:50.131959Z",
     "iopub.status.busy": "2025-06-03T13:21:50.131790Z",
     "iopub.status.idle": "2025-06-03T13:21:50.153300Z",
     "shell.execute_reply": "2025-06-03T13:21:50.152688Z",
     "shell.execute_reply.started": "2025-06-03T13:21:50.131938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def find_optimal_threshold(all_probs, all_labels):\n",
    "    # Sweep a range of thresholds to maximize micro-F1\n",
    "    threshold_range = np.arange(0.20, 0.51, 0.02)  \n",
    "    \n",
    "    f1_scores = []\n",
    "    best_f1 = 0\n",
    "    best_thresh = 0\n",
    "\n",
    "    for t in threshold_range:\n",
    "        temp_preds = (all_probs > t).astype(np.float32)\n",
    "        temp_f1 = f1_score(all_labels, temp_preds, average='micro')\n",
    "        f1_scores.append(temp_f1)\n",
    "        \n",
    "        if temp_f1 > best_f1:\n",
    "            best_f1 = temp_f1\n",
    "            best_thresh = t\n",
    "\n",
    "    f1_scores = np.array(f1_scores)\n",
    "    mean_f1 = f1_scores.mean()\n",
    "    std_f1 = f1_scores.std()\n",
    "\n",
    "    return best_thresh, best_f1, mean_f1, std_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Loop\n",
    "\n",
    "- **Training**: For each epoch, the model is trained on the training set and evaluated on the validation set.\n",
    "- **Metrics**: Tracks training/validation loss, F1 score at fixed and optimal thresholds, learning rate, and number of trainable parameters.\n",
    "- **Threshold Search**: After each epoch, the best threshold is found for the current model state.\n",
    "- **Progress**: ETA and timing information are printed for monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T18:12:55.154006Z",
     "start_time": "2025-05-01T18:06:59.273250Z"
    },
    "execution": {
     "iopub.execute_input": "2025-06-03T13:21:50.154338Z",
     "iopub.status.busy": "2025-06-03T13:21:50.154106Z",
     "iopub.status.idle": "2025-06-03T13:22:29.531402Z",
     "shell.execute_reply": "2025-06-03T13:22:29.530142Z",
     "shell.execute_reply.started": "2025-06-03T13:21:50.154305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_batches_train = len(train_dataloader)\n",
    "num_batches_val = len(val_dataloader)\n",
    "total_runtime = 0\n",
    "history = {'epoch': [],'train_loss': [],'val_loss': [],'f1_at_fixed_thresh': [],'fixed_thresh': [],'best_f1': [],\n",
    "    'best_thresh': [], 'mean_f1' : [], 'f1_std' : [],'lr': [], 'num_trainable_params' : [], 'epoch_time_sec': [],'cumulative_time_min': []}\n",
    "previous_lr = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}:\")\n",
    "    history['epoch'].append(epoch+1)\n",
    "    epoch_start_time = time.time()   \n",
    "\n",
    "    # Learning rate monitoring\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    history['lr'].append(current_lr)\n",
    "    if current_lr != previous_lr:\n",
    "        print(f\"Scheduler updates base (head) learning rate to: {current_lr:.3e}\")     \n",
    "    previous_lr = current_lr\n",
    "    \n",
    "    # Trainable parameters monitoring\n",
    "    num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    history['num_trainable_params'].append(num_trainable_params)\n",
    "\n",
    "    # ------ Training phase ------\n",
    "    model.train()\n",
    "    running_loss_train = 0\n",
    "    print(f\"Begin training {num_trainable_params} parameters.\")\n",
    "\n",
    "    for batch_number, (X, Y) in enumerate(train_dataloader):  # X: Image tensor, Y: Label tensor\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "        # Forward pass: Compute prediction and loss\n",
    "        logits = model(X)\n",
    "        loss = loss_fn(logits, Y)\n",
    "        running_loss_train += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_number + 1)%100==0 or batch_number==0:\n",
    "            # Progress log\n",
    "            print(f\"\\rTrained on batch {batch_number + 1}/{num_batches_train}. Current training loss: {loss.item():.4f}\",\n",
    "                  end=\"\", flush=True)\n",
    "    print(\n",
    "        f\"\\nFinished training for epoch {epoch + 1}. Average training loss: {running_loss_train / num_batches_train:.4f}\")\n",
    "    history['train_loss'].append(running_loss_train / num_batches_train)\n",
    "\n",
    "    # ------ Validation phase ------\n",
    "    model.eval()\n",
    "    running_loss_val = 0\n",
    "    all_probs = []  # for post-processing\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_number, (X, Y) in enumerate(val_dataloader):\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "            # Forward pass: Compute prediction and loss\n",
    "            logits = model(X)       \n",
    "            loss = loss_fn(logits, Y)\n",
    "            running_loss_val += loss.item()\n",
    "\n",
    "            # Compute binary predictions and collect labels\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            preds = (probs > classification_threshold).astype(np.float32)\n",
    "            labels = Y.cpu().numpy()\n",
    "\n",
    "            all_probs.append(probs)\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "            if (batch_number + 1)%25==0 or batch_number==0:\n",
    "                # Progress log\n",
    "                print(\n",
    "                    f\"\\rValidated batch {batch_number + 1}/{num_batches_val}. Current validation loss: {loss.item():.4f}\",\n",
    "                    end=\"\", flush=True)\n",
    "\n",
    "    print(\n",
    "        f\"\\nFinished validation for epoch {epoch + 1}. Average validation loss: {running_loss_val / num_batches_val:.4f}\")\n",
    "    history['val_loss'].append(running_loss_val / num_batches_val)\n",
    "\n",
    "    # ------ Epoch grand result ------\n",
    "    scheduler.step()\n",
    "\n",
    "    # Concatenate all batches and compute F1 score\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_probs = np.vstack(all_probs)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    f1_micro = f1_score(all_labels, all_preds, average='micro')\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} micro F1 score: {f1_micro:.5f} with threshold: {classification_threshold:.2f}.\")  # For intra-epoch comparison\n",
    "    history['f1_at_fixed_thresh'].append(f1_micro)\n",
    "    history['fixed_thresh'].append(classification_threshold)  \n",
    "\n",
    "    # Threshold optimization per epoch\n",
    "    best_thresh, best_f1, mean_f1, std_f1 = find_optimal_threshold(all_probs, all_labels)    \n",
    "    print(f\"Epoch {epoch + 1} optimal micro F1 score: {best_f1:.5f} with threshold: {best_thresh:.2f}.\")\n",
    "    history['best_f1'].append(best_f1)\n",
    "    history['best_thresh'].append(best_thresh)\n",
    "    history['mean_f1'].append(mean_f1)\n",
    "    history['f1_std'].append(std_f1)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # All done. Deal with temporal stuff\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    total_runtime += epoch_duration\n",
    "    avg_epoch_duration = total_runtime / (epoch+1)\n",
    "    remaining_epochs = num_epochs - epoch - 1\n",
    "    eta_seconds = avg_epoch_duration * remaining_epochs\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} completed in {int(epoch_duration)} seconds. ETA: {round(eta_seconds / 60)} minutes.\")\n",
    "    history['epoch_time_sec'].append(epoch_duration)\n",
    "    history['cumulative_time_min'].append(round(total_runtime / 60))\n",
    "    print(\"------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training History and Metrics\n",
    "\n",
    "- **DataFrame**: All tracked metrics are stored in a DataFrame for easy analysis and visualization.\n",
    "- **Interpretation**: We used this table to identify the best epoch, monitor overfitting, and compare loss/F1 trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-03T13:22:29.533203Z",
     "iopub.status.idle": "2025-06-03T13:22:29.533434Z",
     "shell.execute_reply": "2025-06-03T13:22:29.533314Z",
     "shell.execute_reply.started": "2025-06-03T13:22:29.533306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_history = pd.DataFrame(history)\n",
    "print(df_history.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Training Progress\n",
    "\n",
    "- **Loss Curves**: We compared training and validation loss to check for overfitting.\n",
    "- **F1 Scores**: We track F1 at fixed and optimal thresholds to monitor model improvement.\n",
    "- **Threshold Trends**: Observe how the best threshold evolves over epochs.\n",
    "- **Best Epoch**: The epoch with the highest micro-F1 is highlighted for model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-03T13:22:29.534131Z",
     "iopub.status.idle": "2025-06-03T13:22:29.534370Z",
     "shell.execute_reply": "2025-06-03T13:22:29.534248Z",
     "shell.execute_reply.started": "2025-06-03T13:22:29.534239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create subplots with 4 rows and 1 column\n",
    "fig, axes = plt.subplots(4, 1, figsize=(12, 24))\n",
    "\n",
    "# 1st subplot: Train and Validation Loss\n",
    "axes[0].plot(df_history['epoch'], df_history['train_loss'], label='Train Loss', color='blue')\n",
    "axes[0].plot(df_history['epoch'], df_history['val_loss'], label='Validation Loss', color='red')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Train and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# 2nd subplot: F1 score at Fixed Threshold and the Threshold Line\n",
    "axes[1].plot(df_history['epoch'], df_history['f1_at_fixed_thresh'], label='F1 at Fixed Threshold', color='green')\n",
    "axes[1].plot(df_history['epoch'], df_history['fixed_thresh'], label='Fixed Threshold', color='orange', linestyle='--')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('F1 Score')\n",
    "axes[1].set_title('F1 at Fixed Threshold and Threshold Line')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# 3rd subplot: Best F1 Score and Best Threshold\n",
    "axes[2].plot(df_history['epoch'], df_history['best_f1'], label='Best F1 Score', color='purple')\n",
    "axes[2].plot(df_history['epoch'], df_history['best_thresh'], label='Best Threshold', color='brown', linestyle='--')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Score / Threshold')\n",
    "axes[2].set_title('Best F1 Score and Best Threshold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "# 4th subplot: Mean F1 and F1 Standard Deviation\n",
    "axes[3].plot(df_history['epoch'], df_history['mean_f1'], label='Mean F1 across thresholds', color='teal')\n",
    "axes[3].plot(df_history['epoch'], df_history['f1_std'], label='Std of F1 across thresholds', color='darkorange')\n",
    "axes[3].set_xlabel('Epoch')\n",
    "axes[3].set_ylabel('F1 Score')\n",
    "axes[3].set_title('Mean and Std of F1 Across Thresholds')\n",
    "axes[3].legend()\n",
    "axes[3].grid(True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print best epoch based on highest best_f1\n",
    "best_epoch_index = df_history['best_f1'].idxmax()\n",
    "best_row = df_history.loc[best_epoch_index]\n",
    "print(f\"Best epoch based on micro-F1: {int(best_row['epoch'])} \"\n",
    "      f\"with threshold: {best_row['best_thresh']:.2f} \"\n",
    "      f\"and micro F1: {best_row['best_f1']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Training on Full Dataset\n",
    "\n",
    "- **Why retrain?** After selecting the best hyperparameters and threshold, we retrain the model on the entire training set to maximize data usage.\n",
    "- **Parameters**: Use the best epoch's settings for number of epochs and threshold.\n",
    "- **Model Saving**: The final model is saved for future inference and ensembling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = initialize_model('swin_base_patch4_window7_224')  # Reinitialize to get a fresh start\n",
    "\n",
    "loss_fn, optimizer, scheduler = initialize_hyperparameters(model) # Same\n",
    "\n",
    "num_epochs = 6 # Based on validation\n",
    "classification_threshold = 0.32  # Based on the epoch we chose\n",
    "\n",
    "# We will save the model after full training, to use in an ensemble\n",
    "model_save_name = \"SwinV1(3-4)_v15.pth\"\n",
    "submission_name = \"submission_nik_v15_0_1.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Training Loop\n",
    "\n",
    "- **No Validation**: All data is used for training, so no validation metrics are computed.\n",
    "- **Progress**: Training loss and ETA are printed for each epoch, nothing more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = len(full_train_dataloader)\n",
    "total_runtime = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    running_loss_train = 0.0    \n",
    "   \n",
    "    for batch_number, (X, Y) in enumerate(full_train_dataloader):     # X: Image tensor, Y: Label tensor\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "        logits = model(X)\n",
    "        loss = loss_fn(logits, Y)\n",
    "        running_loss_train += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_number + 1)%100==0 or batch_number==0:\n",
    "            # Progress log\n",
    "            print(f\"\\rTrained on batch {batch_number+1}/{num_batches}. Current training loss: {loss.item():.4f}\", end=\"\", flush=True)\n",
    "\n",
    "    print(f\"\\nFinished training for epoch {epoch+1}. Average training loss: {running_loss_train/num_batches:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # All done. Deal with temporal stuff\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    total_runtime += epoch_duration\n",
    "    avg_epoch_duration = total_runtime / (epoch+1)\n",
    "    remaining_epochs = num_epochs - epoch - 1\n",
    "    eta_seconds = avg_epoch_duration * remaining_epochs\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} completed in {int(epoch_duration)} seconds. ETA: {round(eta_seconds / 60)} minutes.\")\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "\n",
    "# Save the fully trained model to use in the ensemble \n",
    "torch.save(model.state_dict(), model_save_name) # Note to self: the model was trained on 2 GPUs so there is a \"module.\" prefix on its state dict keys\n",
    "print(f\"Model saved as {model_save_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Prediction and Submission\n",
    "\n",
    "- **Inference**: The trained model predicts labels for each test image.\n",
    "- **Thresholding**: Predictions are binarized using the selected threshold.\n",
    "- **Fallback**: If no label is assigned to an image, the most confident label is set to ensure every image has at least one label.\n",
    "- **Submission**: Results are saved in the required CSV format for competition submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_filenames = []\n",
    "times_fallback = 0\n",
    "\n",
    "num_batches = len(test_dataloader)\n",
    "with torch.no_grad():\n",
    "    for batch_number, (X, filenames) in enumerate(test_dataloader):\n",
    "        X = X.to(device)\n",
    "        logits = model(X)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        preds = (probs > classification_threshold).astype(int)  \n",
    "\n",
    "        # Fallback: Ensure at least one label is set per sample\n",
    "        for i in range(preds.shape[0]):\n",
    "            if preds[i].sum() == 0: # if no labels are present for this image\n",
    "                times_fallback += 1                \n",
    "                max_idx = np.argmax(probs[i]) # set the highest probability label\n",
    "                preds[i][max_idx] = 1\n",
    "        \n",
    "        all_preds.append(preds)\n",
    "        all_filenames.extend(filenames)\n",
    "        \n",
    "        print(f\"Predicted batch {batch_number+1}/{num_batches}.\")\n",
    "\n",
    "all_preds = np.vstack(all_preds)\n",
    "print(f\"Total number of fallbacks (no labels set through thresholding): {times_fallback}/1000. Fallback rate: {times_fallback / 1000:.2%}\")\n",
    "\n",
    "# Save submission. Good luck!\n",
    "submission_df = pd.DataFrame(all_preds, columns=[str(i) for i in range(498)])\n",
    "submission_df.insert(0, \"Filename\", all_filenames)\n",
    "submission_df.to_csv(submission_name, index=False)\n",
    "print(f\"Submission saved as {submission_name}.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11657716,
     "sourceId": 97683,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
