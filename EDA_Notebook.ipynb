{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "275ce0cb",
   "metadata": {},
   "source": [
    "# Final EDA Notebook\n",
    "\n",
    "This notebook provides a comprehensive exploratory data analysis (EDA) of the food classification dataset. The goal is to understand the data distribution, label structure, image properties, and to visualize both ground truth and model predictions. This EDA supports model development and helps identify potential issues or opportunities for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T14:06:24.676322Z",
     "start_time": "2025-05-11T14:06:21.592298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from statistics import multimode\n",
    "\n",
    "# Third-party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Allow duplicate OpenMP libraries (fixes some multi-threading issues on some systems)\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd95b31",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "- **Device selection**: Automatically uses GPU if available, otherwise falls back to CPU.\n",
    "- **Directory paths**: Set up paths for training images, test images, label file, and category names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb649f2-f64f-4b8f-a862-eabf16236cb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T14:06:24.712920Z",
     "start_time": "2025-05-11T14:06:24.676322Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"CUDA Devices: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train_dir = 'images_train'\n",
    "images_test_dir = 'images_test'\n",
    "labels_dir = 'train_onehot.csv'\n",
    "label_names_dir = 'categories_new.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc0fbe0",
   "metadata": {},
   "source": [
    "## 2. Data Loading \n",
    "\n",
    "- **DataFrames**: Load label and category data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0432103301006f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T14:06:25.856191Z",
     "start_time": "2025-05-11T14:06:24.864168Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(labels_dir)\n",
    "category_df = pd.read_csv(label_names_dir)\n",
    "\n",
    "print(\"Dataset shape:\", labels_df.shape)\n",
    "print(\"First rows:\\n\")\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca64625",
   "metadata": {},
   "source": [
    "## 3. Label Analysis\n",
    "\n",
    "- **Label matrix**: Analyze the distribution of labels per image and images per label.\n",
    "- **Visualization**: Plot the number of labels per image and the frequency of each label in the dataset.\n",
    "- **Insights**: Identify class imbalance and multi-label characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba126a41a6baf79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T14:06:26.197594Z",
     "start_time": "2025-05-11T14:06:25.862760Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract label matrix (numpy array, shape: [num_samples, 498])\n",
    "label_matrix = labels_df.iloc[:, 1:].values\n",
    "print(\"Label stats:\")\n",
    "\n",
    "# Labels per image\n",
    "labels_per_image = label_matrix.sum(axis=1)\n",
    "print(f\"Labels per image: mean={labels_per_image.mean():.2f}, min={labels_per_image.min()}, max={labels_per_image.max()}\")\n",
    "\n",
    "# Build a DataFrame too\n",
    "labels_per_image_counts = pd.Series(labels_per_image).value_counts().sort_index()\n",
    "label_count_df = pd.DataFrame({\n",
    "    'Number of Labels': labels_per_image_counts.index,\n",
    "    'Image Count': labels_per_image_counts.values\n",
    "})\n",
    "label_count_df['Cumulative %'] = label_count_df['Image Count'].cumsum() / label_count_df['Image Count'].sum() * 100\n",
    "\n",
    "# Also make a nice plot of the distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=label_count_df['Number of Labels'], y=label_count_df['Image Count'])\n",
    "plt.title(\"Distribution of Labels per Image\")\n",
    "plt.xlabel(\"Number of Labels\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nImages by number of labels\")\n",
    "label_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images per label\n",
    "images_per_label = label_matrix.sum(axis=0)\n",
    "print(f\"Images per label: mean={images_per_label.mean():.2f}, min={images_per_label.min()}, max={images_per_label.max()}\")\n",
    "\n",
    "# Build a DataFrame too\n",
    "label_freq_df = pd.DataFrame({\n",
    "    'Label': category_df['name'],\n",
    "    'Image Count': images_per_label\n",
    "})\n",
    "label_freq_df = label_freq_df.sort_values(by='Image Count', ascending=False).reset_index(drop=True)\n",
    "label_freq_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b9752",
   "metadata": {},
   "source": [
    "## 4. Image Size Exploration\n",
    "\n",
    "- **Image dimensions**: Analyze the width and height of all training images.\n",
    "- **Visualization**: Plot the distribution of image sizes to inform preprocessing and augmentation choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878d0e2b0394b759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T14:06:29.405554Z",
     "start_time": "2025-05-11T14:06:26.207456Z"
    }
   },
   "outputs": [],
   "source": [
    "img_filenames = labels_df.iloc[:, 0].values\n",
    "\n",
    "widths, heights = [], []\n",
    "\n",
    "for filename in tqdm(img_filenames):\n",
    "    with Image.open(os.path.join(images_train_dir, filename)) as img:\n",
    "        w, h = img.size\n",
    "        widths.append(w)\n",
    "        heights.append(h)\n",
    "\n",
    "# Summary\n",
    "print(\"Image dimension stats:\")\n",
    "print(f\"Width: mean={np.mean(widths):.2f}, median: {np.median(widths)}, min={np.min(widths)}, max={np.max(widths)}, mode={multimode(widths)}\")\n",
    "print(f\"Height: mean={np.mean(heights):.2f}, median: {np.median(heights)}, min={np.min(heights)}, max={np.max(heights)}, mode={multimode(heights)}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(widths, color=\"blue\", label=\"Widths\")\n",
    "sns.histplot(heights, color=\"orange\", label=\"Heights\")\n",
    "plt.legend()\n",
    "plt.title(\"Image Dimensions (Pre-Resize)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b5a68",
   "metadata": {},
   "source": [
    "## 5. Dataset and Dataloader Construction\n",
    "\n",
    "- **Custom Dataset**: Defines a PyTorch Dataset for both training and test images, supporting flexible transforms.\n",
    "- **Dataloaders**: Efficiently load images in batches for analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd18f6b27fa8c03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T14:07:54.473819Z",
     "start_time": "2025-05-11T14:07:53.940919Z"
    }
   },
   "outputs": [],
   "source": [
    "image_dim_px = 224\n",
    "\n",
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_csv = None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_training = labels_csv is not None # If labels_csv is provided, it's a training dataset. Else, it's a test dataset.\n",
    "\n",
    "        if self.is_training:\n",
    "            # Load training data\n",
    "            self.labels_df = pd.read_csv(labels_csv)      \n",
    "            self.filenames = self.labels_df.iloc[:, 0].values  # image filenames\n",
    "            self.labels = self.labels_df.iloc[:, 1:].values.astype('float')  # one-hot labels\n",
    "        else:\n",
    "            self.filenames = sorted(os.listdir(img_dir))\n",
    "            self.labels = None  # No labels for the test set\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Find the image file path and open it \n",
    "        img_path = os.path.join(self.img_dir, self.filenames[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_training:\n",
    "            # For training data, return the image and its label\n",
    "            label = torch.tensor(self.labels[idx])\n",
    "            return image, label\n",
    "        else:\n",
    "            # For test data, return the image and its filename\n",
    "            return image, self.filenames[idx]  \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_dim_px, image_dim_px)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = FoodDataset(images_train_dir, labels_dir, transform=transform)  \n",
    "test_dataset = FoodDataset(images_test_dir, labels_csv=None, transform=transform)\n",
    "\n",
    "batch_size = 64  \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3d388",
   "metadata": {},
   "source": [
    "## 6. Visualization Utilities\n",
    "\n",
    "- **plot_with_labels**: Visualize random samples from the dataset, showing ground truth or predicted labels.\n",
    "- **Usage**: Supports both training and test sets, and can display model predictions from submission files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d76ffefd55b3d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T14:08:26.822153Z",
     "start_time": "2025-05-11T14:08:26.418849Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_with_labels(dataset, indices, submission_df=None):\n",
    "    num_samples = len(indices)\n",
    "    plt.figure(figsize=(3 * num_samples, 4))  # dynamically scale width\n",
    "\n",
    "    # If using submission_df, build a filename-to-row lookup \n",
    "    if submission_df is not None:\n",
    "        filename_to_row = {fname: i for i, fname in enumerate(submission_df.iloc[:, 0].values)}\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        image, label_or_filename = dataset[idx]\n",
    "        image_np = image.permute(1, 2, 0).numpy()  # CHW -> HWC for plotting\n",
    "\n",
    "        plt.subplot(1, num_samples, i + 1)\n",
    "        plt.imshow(image_np)\n",
    "        plt.axis('off')\n",
    "\n",
    "        if submission_df is not None:\n",
    "            # Test set: label_or_filename is the filename\n",
    "            filename = label_or_filename\n",
    "            row_idx = filename_to_row.get(filename, None)\n",
    "            if row_idx is not None:\n",
    "                label_row = submission_df.iloc[row_idx, 1:].values.astype(float)\n",
    "                label_indices = np.where(label_row == 1)[0]\n",
    "                label_names = [category_df['name'].iloc[j] for j in label_indices]\n",
    "                if not label_names:\n",
    "                    label_names = [\"(No label assigned)\"]\n",
    "            else:\n",
    "                label_names = [\"Not found\"]\n",
    "        else:\n",
    "            # Train set: label_or_filename is a tensor\n",
    "            label_indices = np.where(label_or_filename.numpy() == 1)[0]\n",
    "            label_names = category_df['name'].iloc[label_indices].tolist()\n",
    "        # Make title string\n",
    "        title = \"\\n\".join(label_names)\n",
    "        plt.title(title, fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Show random samples from the dataset\n",
    "num_samples = 7\n",
    "random_indices = np.random.choice(len(train_dataset), num_samples, replace=False)\n",
    "plot_with_labels(train_dataset, random_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d502b6f",
   "metadata": {},
   "source": [
    "## 7. Post-Submission Analysis\n",
    "\n",
    "- **Prediction visualization**: Plot random test images with predicted labels from a submission file.\n",
    "- **Unlabeled images**: Count and report the number of test images with no labels assigned in a submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a70cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-submission exploration: plot random predictions from submission file\n",
    "\n",
    "# Load submission CSV \n",
    "submission_df = pd.read_csv(\"ensemble_submission_nik_v11_1.csv\")\n",
    "\n",
    "num_samples = 7\n",
    "random_indices = random.sample(range(len(test_dataset)), num_samples)\n",
    "plot_with_labels(test_dataset, random_indices, submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-submission exploration: count number of images with no labels assigned from submission file\n",
    "\n",
    "submission_df = pd.read_csv(\"ensemble_submission_nik_v11_1.csv\")\n",
    "no_label_count = submission_df.iloc[:, 1:].sum(axis=1).value_counts().get(0, 0)\n",
    "print(f\"Number of images with no labels assigned in submission: {no_label_count}/{len(submission_df)} ({no_label_count / len(submission_df) * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddedb08",
   "metadata": {},
   "source": [
    "## 8. Normalization Metrics\n",
    "\n",
    "- **Mean and std calculation**: Compute per-channel mean and standard deviation for the training set.\n",
    "- **Purpose**: Used for normalization in model training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d584f439f5c86ae6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T14:12:12.391053Z",
     "start_time": "2025-05-11T14:08:41.557162Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mean_std(dataloader):\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    total_images = 0\n",
    "\n",
    "    for images, _ in tqdm(dataloader):\n",
    "        images.to(device)\n",
    "        batch_samples = images.size(0)  \n",
    "        images = images.view(batch_samples, images.size(1), -1)  # (B, C, H*W)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images += batch_samples\n",
    "\n",
    "    mean /= total_images\n",
    "    std /= total_images\n",
    "    return mean, std\n",
    "\n",
    "mean, std = get_mean_std(train_dataloader)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811aa6bd",
   "metadata": {},
   "source": [
    "## 9. Model / Ensemble Disagreement Analysis\n",
    "\n",
    "- **Crosstabulation**: Compare multiple submission files to analyze pairwise model or ensemble disagreements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2b5e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstabulate pairwise disagreements between submission files\n",
    "\n",
    "# Create list of submission files here\n",
    "appends = ['13_0_1', '15_0_1', '16_0_1', '17_0_1','18', '19', '20']\n",
    "submission_files = ['submission_nik_v' + append + '.csv' for append in appends]\n",
    "submission_files.append('submission_billy_swin_60f1.csv')\n",
    "\n",
    "# Read all submissions into a list of DataFrames\n",
    "submissions = [pd.read_csv(f) for f in submission_files]\n",
    "\n",
    "# Ensure all have the same order and columns\n",
    "for df in submissions[1:]:\n",
    "    assert (df[\"Filename\"].values == submissions[0][\"Filename\"].values).all(), \"Filenames do not match!\"\n",
    "\n",
    "# Stack label predictions (excluding filename column)\n",
    "preds = [df.iloc[:, 1:].values for df in submissions]\n",
    "preds = np.stack(preds, axis=0)  # shape: (num_models, num_images, num_labels)\n",
    "\n",
    "num_models = len(submissions)\n",
    "disagreement_matrix = np.zeros((num_models, num_models), dtype=int)\n",
    "\n",
    "for i in range(num_models):\n",
    "    for j in range(num_models):\n",
    "        # Count number of images where any label prediction differs between model i and model j\n",
    "        disagreement_matrix[i, j] = np.sum(np.any(preds[i] != preds[j], axis=1))\n",
    "\n",
    "# Create a DataFrame for pretty display\n",
    "labels = []\n",
    "for fname in submission_files:\n",
    "    match = re.search(r'(\\d{2})', fname)\n",
    "    if match:\n",
    "        labels.append(match.group(1))\n",
    "    else:\n",
    "        labels.append(fname)  # fallback to filename if no 2-digit number found\n",
    "\n",
    "crosstab_df = pd.DataFrame(disagreement_matrix, index=labels, columns=labels)\n",
    "print(\"Pairwise number of images with any label disagreement between models:\")\n",
    "display(crosstab_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
